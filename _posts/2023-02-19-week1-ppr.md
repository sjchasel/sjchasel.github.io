---
layout: post
title: 【论文阅读】weekly paper reading - 7
categories: 论文笔记
keywords: Bio, NLP
mathjax: true
---


# C5T5: Controllable Generation of Organic Molecules with Transformers

- motivation：在原子级别上做分子优化，所得到的分子可能很难合成。因此希望以官能团为基本编辑单位进行分子优化。

- method：借助IUPAC表示，训练时在IUPAC前拼上表示分子性质水平的字符（分成了三个水平：\<low\>、\<med>、\<high\>），进行MLM形式的训练。模型学习到了分子性质和分子结构的对应关系。inference时，将前面的字符替换成想要的水平，然后mask想要替换的官能团，让模型生成新的分子。



# Transformer‑based artificial neural networks for the conversion between chemical notations


用transformer进行IUPAC和SMILES的双向翻译。开源了从IUPAC到SMILES的模型，反向的操作有其他的开源工具。

# Graph Contrastive Learning with Augmentations

code: https://github.com/Shen-Lab/GraphCL

## Motivation

之前的研究中对GNN的训练任务都需要有标签的数据，但像生物领域，图结构数据的标签通常需要做湿实验获得，成本很高。因此需要探索如何在图数据上做自监督的预训练。

## Method

本文提出四种图数据增强的策略（比率都设成0.2）：
1. Node dropping
级别：节点、边
先验条件：节点的缺失不影响图的语义
做法：随机丢失一些节点和它们之间的边
2. Edge perturbation
级别：边
先验条件：图的语义对连通关系有一定的鲁棒性
做法：随机增加或减少一定比例的边来扰乱图的连通性
3. Attribute masking
级别：节点
先验条件：丢失一些节点的属性对模型的预测影响不大
做法：mask一些节点的特征，让模型从周围的信息来推断这个节点的信息
4. Subgraph
级别：节点、边
先验条件：局部结构可能蕴含着完整的语义
做法：使用随机游走算法从图中采样一个子图

再加上对比学习，最大化来自同一个graph的两个增广数据的互信息。

## 结论

1. 在对比学习中对图数据进行数据增强很有用
2. 组合不同类型的数据增强能学到更有泛化性的特征
3. 边的扰动对社交网络数据有利，但对分子数据有负作用
4. 密度大的图适合用attribute masking 
5. node dropping和subgraph对不同数据集的泛化性最强




# G-Mixup: Graph Data Augmentation for Graph Classification


- ICLR拒收，投ICML22被评了杰出论文。但是里面的理论只有国外一些文献有解释，太抽象了。只能理解一下基本的思想：

- 这个工作是做graph数据的mixup，在class-level上。因为各个graph的节点个数不同、拓扑信息不同，很难用传统的方法进行mixup。这篇文章引入graphon（图元）这个概念，表示着一类graph的特征。图元可以看作是规则的矩阵，矩阵上的元素代表两个节点之间有边的概率。将两种图元进行mixup，获得了一个混合图元，再从混合的图元中采样生成新的图，就得到了mixup后的图数据。

- 如果能对分子进行有区别度的分类，这个方法应该可以快速试试，代码挺少，看见GitHub的issue里有人说在蛋白质数据上的表现不错。

# MixGen: A New Multi-Modal Data Augmentation

李沐团队的论文，对多模态数据进行mixup。  
对多模态数据做数据增强的要求：保持重要特征仍然是对齐/匹配的：比如一张图所对应的文本是：a **white** dog playing in the **right** corner of the **green** lawn。在对图片进行裁剪、颜色变换、翻转等操作后应该同时改变文字中加粗的描述。

![](/images/blog/mixgen.png)

本文的方法很简单，将图像进行插值，文本直接拼接。这样图像的信息混合在插值后的图片中，文本的信息全部保留。因此它们还是匹配的。作者也尝试了多个变种，比如随机选一个图片/随机选一条文本/将部分文本截断后拼接，还尝试了在embedding-level上进行插值和拼接，最终还是在原始数据上进行图像的插值和文本的拼接效果最好。





# ACL22 STEMM: Self-learning with Speech-text 

多模态数据的特征空间差距很大，希望用mixup让不同模态的数据学到一个统一的特征空间。因为是语音翻译到文本的任务，两种序列是有线性的对齐关系的。所以能以对齐的子序列为单位进行mixup，有点像多语言的code switch。


因为分子是graph形式，各个节点之间有拓扑关系。大部分官能团所对应的只有一个关键原子，只有在它经过了图神经网络的编码才包含了周围子结构的信息，所以在编码过几层再进行mixup比较好（我们的模型没有decoder，所以不能像原文一样在编码结束再mixup）。但如果是n个节点对应m个token，它们之间没法1对1替换，如果是池化后再mixup，可能会让图上的不同节点学到过于相似的特征。
 