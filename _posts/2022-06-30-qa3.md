---
layout: post
title: 【论文阅读】三篇问答相关的生成类工作
categories: ["论文笔记", "NLP"]
mathjax: true
---

# Don’t Parse, Generate! A Sequence to Sequence Architecture for Task-Oriented Semantic Parsing

2020WWW的论文。对话系统场景下，理解人的query需要完成意图识别和槽填充两个任务（但这边好像把这两步都当成槽填充？），相比于原始的语义解析方法，作者采用seq2seq的模型来生成结果，可以处理一些更复杂的query。

## Motivation

在对对话query进行语义解析的过程中，面对简单流畅的结构，判断一下意图，标注一下slot value就好了。面对稍微复杂一些的结构，将其构造成句法分析树。但面对实体不连续或重叠的情况，就很难构造这样的树。
作者提出的seq2seq模型可以统一解决所有query的情况。


## Method

### Query Formulation

在seq2seq中，输入仍然是query，输出是意图和槽的拼接。比如：

![example](/images/blog/generate_dialog_example.png)


在target的slot中， $@ptr_n$ 表示是原文中的第n个字符。

### Model Architecture

![model](/images/blog/generate_dialog_model.png)

encoder是个BERT，decoder也就是transformer的decoder。这个模型跟之前两篇ACL的一模一样嘛。没啥好说的了。

# Can Generative Pre-trained Language Models Serve as Knowledge Bases for Closed-book QA?

ACL2021。一篇分析性论文，探究预训练模型里包含的知识能不能帮助closed-book QA任务。closed-book咋说？我接下来就说闭卷吧。
呜呜呜好烦分析性论文啊，感觉要看很多很多文字。

##  Motivation

预训练模型能不能当作 knowledge bases 使用，来帮助闭卷QA？

现有的工作的其他问题是：
1. 使用的数据集只包含问答对，我们不知道在预训练模型训练的时候学习到了哪些知识。为了探究到底用没用到预训练模型里的知识，我们应该控制预训练模型包含的知识。
2. 现在探究这个方面的工作都在很小的benchmark上，训练集和测试集由很大重叠，所以不知道效果是因为预训练模型里的知识真的发挥了作用而提高，还是因为模型记住了训练集的答案。

所以作者根据SQuAD构造了一个更大的闭卷QA数据集，并且每个问答对都有相关的维基百科里的段落用来预训练。虽然BART在现在的benchmark上可以达到25%的准确率，但在这个新数据集上只有1.5%。说明直接使用BART来完成这个闭卷任务还是很有挑战性的。接下来作者探究：
1. BART能不能准确记住预训练的知识。
2. BART能不能使用记住的预训练知识来帮助回答问题。


## Method

为了探究以上两个方面，流程如下图所示：

![process](/images/blog/qa_process.png)

1. 对于第一个问题：
+ LM-finetuning：继续使用维基百科里的相关段落对模型进行预训练。
+ reciting：使用语言建模任务来测试模型记住了多少。
+ 结论：用来预训练的段落越多，模型能记住的知识飞速下降。
2. 对于第二个问题：
+ 使用LM-finetuning后的BART（为了记住更多知识，没有用太多段落进行预训练）来回答相关问题，效果很差。
+ 结论：BART不知道如何利用预训练知识来回答问题。并且QA数据集fine tune时，还会影响之前记住的相关知识。

但作者发现了一些可以改进的方向：
1. 简单地把相关段落添加在test output里（应该是作为上文？），BART就能检索到相关知识，做出正确回答。
2. 需要解耦LM-finetuning和QA-finetuning两个阶段，模型可以保留更多学到的知识。

之后应该是使用实验具体阐述。

## Experiment

### Using SQuAD for Closed-book QA

好吧，这一节感觉就是在说明文章要研究的问题是真实存在的。

### Task Design

这一节跟Method提到的差不多。

![process](/images/blog/qa_task.png)

+ LM-finetune和Recite是教师的教学和背诵重点过程，在Knowledge Memory中重点讲。
+ QA-finetune和Test closed-book question是教师给的练习/小测和最后的考试，在Question Answering中讲。


### Knowledge Memory

#### Training of LM-finetuning

在BART上，只用相关段落进行token infilling任务的预训练。

#### Testing of LM-finetuning (Reciting)

mask相关段落里的一些词，让模型去还原。mask的都是相关问答的答案，如果模型可以还原，说明模型在接下来的QA测试中肯定是记住了所需的有用信息。

![recite](/images/blog/qa_recite.png)

1. 这个任务无法靠猜
2. 虽然给了全部的知识，但BART竟然只提高了0.5%的效果！

![recite2](/images/blog/qa_recite2.png)

1. 通过LM-finetune，BART是可以记住很多知识的
2. 要记的东西越多，BART忘的越多

在接下来的分析中，使用前三列的设置，因为BART可以记住超过50%的知识。在这个基础上，看看模型能不能使用记住的知识来回答问题，需要回答的问题都是在LM阶段见过相关段落的。


### Question Answering

指标：Exact Match (EM) 、Human Evaluation (HE) and F1

#### Overall Results 

![over](/images/blog/qa_51.png)

主实验结果在前两行。RA是reciting accuracy。

1. 第一行。与RA相比，HE也太低了。说明模型无法很好地利用学到的知识。
2. 比较前两行的HE，在经过LM阶段后再QA还是有提升的，但是提升不大。

可能的原因有：
1. 模型无法激活有关的信息来回答问题
2. 记住的有关信息在QA阶段被破坏了

#### Strengthening Memory Retrieval

采用  QA-bridge-tune 来提升知识检索的效果。就是在输出前拼接上相关段落，使得相关信息作为回答的上文。这样微调后BART先输出记住的相关段落，再输出正确答案。

![bridge](/images/blog/qa_bridge.png)


#### Influence of QA on Memory

为了探究QA finetune 阶段会不会破坏学到的知识，使用QA finetuned 模型去做recite任务。

![recite3](/images/blog/qa_recite3.png)

破坏的程度很大，可能的原因：
1. 存储的知识和参数有关，QA调过后参数就不一样了。
2. 知识仍然存在，但模型的输出空间不一样了。

采用的方法是加上一些prefix和suffix，来让模型区分，学到的知识要放在哪个空间中。也就是在LM阶段，输入的passage都要加上 \<PASSAGE> 和 \</PASSAGE>，在QA阶段，问题和回答都要加上 \<QUESTION> \<\QUESTION> \<ANSWER> \<\ANSWER>。


# Answer Generation for Retrieval-based Question Answering Systems

ACL2021 Findings。

## Motivation

作者质疑的是在问答任务中，answer sentence selection (AS2) models 可以基于检索出来的数据选择一个包含正确答案的回答，但是挑选出来的回答具有以下缺点：
1. 它可能包含了正确的信息，但却不是在回答用户的问题；
2. 它可能非常长，包含很多术语，很难理解。

比如在用于训练AS2模型的数据集WikiQA中，问风能是什么的答案：Wind power is the conversion of wind energy into a useful form of energy, such as using wind turbines to make electrical power, windmills for mechanical power, wind pumps for water pumping... 

于是作者提出的模型，以AS2 model作为其中的组件，接上一个seq2seq模型，基于检索出来的top 5个候选句子来生成一句正确且流畅的回答。

## Method

作者用了2020的TANDA模型来作为selector选择候选句子。然后生成模型根据问题和候选句子的信息来生成答案，比如：

![example](/images/blog/qa_example.png)

最后的答案可以从多个候选句中提取出有用的信息综合在一起，并针对问题流畅地回答。

模型就是使用预训练模型T5（UnifiedQA T5）或者BART（Large）在数据集上进行fine-tune。src是问题拼上五个候选回答；tgt，如果是有人工组合的答案，那么直接训练就好，如果没有人工组合的答案，就选一个答案作为tgt，然后把它从候选句子中去掉。

## Experiment


### How to Fine-tune GenQA?

有MSNLG和WQA两个数据集的大小满足去fine-tune模型，探索了不同fine-tune策略对结果的影响：
1. 只用WQA
2. 只用MSNLG
3. 都用
4. 采用transfer-then-adapt策略，先用MSNLG，再用WQA

![exp1](/images/blog/qa_exp1.png)

作者比较的baseline正是作为自己模型一部分的TANDA。这里的accuracy是说有没有回答正确那个问题，但我不知道这个在问答里具体是怎么计算的，可能是匹配一下正确答案有没有在回答里？作者拼了一个生成组件的模型能在TANDA上有很大提高，说明生成组件能够准确地选择候选句里那些信息是对这个问题有用的。

因为MSNLG是由人类进行高质量标注的数据集，而WQS只是一个AS2数据集，所以采用MSNLG会有更好的效果。作者说以后再探索如何利用现在这些AS2数据集。

### Comparison between AS2 and GenQA

![exp2](/images/blog/qa_exp2.png)

这个实验，其实就像主实验？比较TANDA和自己提出的GenQA。TANDA很高的Hit@5说明了候选句中是几乎一定包含正确信息的，但低Acc说明它可能会选错。而GenQA可以很好地提取有用的信息。
GenQA可以更简洁地表述答案。比如对于问题：What year did Isaac Newton die?
TANDA回答：Sir Isaac Newton (25 December 1642–20 March 1727) was an English physicist and mathematician.
GenQA回答：Isaac Newton died in 1727.