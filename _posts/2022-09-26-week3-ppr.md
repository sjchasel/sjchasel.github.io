---
layout: post
title: 【论文阅读】weekly paper reading - 2
categories: 论文笔记
keywords: NLP, NMT, paraphrase
mathjax: true
---

# Paraphrasing Academic Text: A Study of Back-translating Anatomy and Physiology with Transformers

+ 使用谷歌翻译API为专业书籍anatomy and physiology做回译。在做回译获得paraphrase时，中间的那个语言叫做pivot language。作者尝试了很多pivot language，发现通过捷克语（Czech）获得的paraphrase会在词级别做更多改动，而俄罗斯语（Russian）则会在短语级别上做更多改动。  

+ 当收集平行句对后，用T5-base进行fine-tune。竟然用一块1080Ti只需要3.5h！还以为T5很难训。

# Domain-Specific Paraphrase Extraction
+ 衡量两个文本为复述的概率是：$p(e_2|e_1) \approx \sum_f p(e_2|f)p(f|e_1)$  
    + $p(e_2|f)$和$p(f|e_1)$分别为两个反向的翻译模型的概率，f为过渡的语种  

+ 衡量一个文本是否属于某个领域的分数是：$\sigma_i=H_{t g t}\left(s_i\right)-H_{g e n}\left(s_i\right)$  
    + 第一项为这个句子在这个领域的文本上训练出来的语言模型的交叉熵，第二项为这个句子在通用领域上训练的语言模型的交叉熵  


# COLING22 Learning Decoupled Retrieval Representation for Nearest Neighbour Neural Machine Translation  

+ Motivation：hidden state在KNN-MT中需要发挥两个作用：（1）作为token的semantic vector；（2）作为检索到这个token的retrieval vector。这种做法阻碍了性能的提高，需要将这两种表示分开。  

+ Method：使用一个FFN层将hidden state映射到一个新的向量z上作为retrieval vector，再用对比学习学习z更好的表示。  
