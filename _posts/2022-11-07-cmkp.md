---
layout: post
title: 【论文阅读】EMNLP 2020 Cross-Media Keyphrase Prediction： A Unified Framework with Multi-Modality Multi-Head Attention and Image Wordings
categories: 论文笔记
keywords: NLP, KPG
mathjax: true
---

![](/images/blog/cmkp.png)


多模态kp生成，用的数据是推特的post。不写motivation了。

# Method



## Overview

![](/images/blog/cmkp_model.png)

+ One2One paradigm
+ encode a text-image tweet into three modalities: text（post的文本）, attribute（从图像预测出的文本）, and vision（图像）
+ 提出新的attention对三种模态进行交互
+ 会有一个分类器，和一个广泛用在kp中的生成器。这个生成器中包含着从整个vocab的生成和从输入文本中的copy，二者结合是生成器的输出。生成器的输出和分类器的输出又做结合，成为这个模型最后的输出

## 特征提取

+ 文本
    + OCR Text：用07年公开的OCR工具包提取图像中的文本，以<SEP>分隔加在post的后面
    + post + ocr 编码：用在推特数据上预训练的glove向量，经过双向GRU编码出textual memory bank，维度为l_src * hidden dim
+ 图像
    + 原始图像有grid-level和object-level两种feature。前者通过VGG-16 Net提取7 * 7的特征，后者使用在Visual Genome上预训练的Faster-RCNN进行目标检测和特征的提取。在作者提出的模型中vgg的grid-level效果更好。
    + 每个 feature map都经过mlp投影到向量上，也获得了一个 visual memory bank，长度是image regions（vgg中有7 * 7个region）（或 objects）的个数
+ 图像的Attribute
    + 在MS-COCO 2014 caption数据集上，基于Resnet-152 features ，训了一个 attribute predictor；attribute label的构造，是caption里的名词和形容词
    + 预测出来的前五个attribute label通过线性层转换成特征向量，形成attribute memory bank，长度是5
    + 这个模态是用来捕捉图像的 high-level semantic concepts

## Multi-modality Multi-Head Attention

![](/images/blog/cmkp_attention.png)


- 每个模态只有一个query向量，是通过max/mean pooling
- 两两attention
  - text为q；attribute和Visio为kv
  - attribute为q；text为kv
  - Vision为q；text为kv
- 加起来过线性层，获得c_fuse

## keyphrase prediction

### keyphrase classification

c_fuse -- mlp -- softmax

### keyphrase generation (generate + copy)

在one2set中，transformer decoder的过程是
【Decoder input】 ut  
每层的cross-attention计算：  
q=ut/上一层的ht，k=encoder_outputs，v=encoder_outputs  --> attention dist  
Attn dist * encoder_outputs = ht(decoder hidden state)  
最后一层的attn dist的第一个head作为copy dist  
最后一层输出的ht计算gen dist  
最后一层输出的ht决定权重  

在本文中，decoder的计算过程是  
【Decoder input】ut 
【经过GRU 后 Hidden state】st
加上注意力机制：q=st，k=encoder_outputs，v=encoder_outputs  --> attention dist
Attn dist * encoder_outputs = ct
Attn dist作为copy dist
[ut;st;ct+c_fuse]计算gen dist（但是在代码里似乎只用了[st;ct+c_fuse]）
[ut;st;ct+c_fuse]决定权重

除此之外，对copy机制的增强在于：  
- 从分类器中检索topk个预测，把它们变成word序列，把它们分类的logits softmax到一个小的词表的分布上。这个分布的维度是unique word的个数还是所有word的个数我需要再看看代码（论文里用的维度看起来是整个序列的长度，也就是所有word的个数）
- 这个分布再和attention分布做个加权，这个权重是超参数。

![](/images/blog/cmkp_weight.png)

在训练的第一阶段，a=1，b=0。在第二阶段，a=b=0.5。实际上也没有乘0.5，导致最后的概率分布相加不为1。



## 训练过程


![](/images/blog/cmkp_loss.png)

- 首先将分类器和生成器联合训练，不合并他们的输出，希望能训一个好的分类器。这个过程是15个epoch。
- 再将分类器和生成器的输出合并，微调5个epoch。这个过程中固定分类器的参数，只训生成器的参数。

## 具体实现

作者公开的代码里并没有这篇论文描述的模型，是一个不使用attribute的模型，并且只将image作为query，text作为key和value计算一个简单的attention，效果已经接近原论文了。  

仔细看论文可以发现作者对attribute做的消融实验只在去掉了生成器，只保留分类器的模型上，并没有在论文提出的模型上做。在有生成器的时候，attribute这个特征可能更加没有效果了。

# Experiment

![](/images/blog/cmkp_exp1.png)

作者说没有这方面的研究，所以没有baseline可比，所以主实验就是一堆消融实验。但是这很像Hashtag Recommendation等工作啊，用到的数据形式都一样。